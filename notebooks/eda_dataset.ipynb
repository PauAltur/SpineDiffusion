{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Workspace setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import open3d as o3d\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Count number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"P:\\\\Projects\\\\LMB_4Dspine\\\\back_scan_database\")\n",
    "\n",
    "backscan_dirs = glob.glob(str(path / \"**\" / \"*.ply\"))\n",
    "metadata_dirs = glob.glob(str(path / \"**\" / \"*.json\"))\n",
    "\n",
    "dirs_df = pd.DataFrame({\"backscan\": backscan_dirs, \"metadata\": metadata_dirs})\n",
    "dirs_df[\"raw\"] = dirs_df[\"backscan\"].str.contains(\"raw\")\n",
    "dirs_df[\"processed\"] = dirs_df[\"backscan\"].str.contains(\"processed\")\n",
    "\n",
    "dirs_df[\"balgrist\"] = dirs_df[\"backscan\"].str.contains(\"balgrist\")\n",
    "dirs_df[\"croatian\"] = dirs_df[\"backscan\"].str.contains(\"croatian\")\n",
    "dirs_df[\"italian\"] = dirs_df[\"backscan\"].str.contains(\"italian\")\n",
    "dirs_df[\"ukbb\"] = dirs_df[\"backscan\"].str.contains(\"ukbb\")\n",
    "\n",
    "dirs_df.groupby(\"raw\")[[\"balgrist\", \"croatian\", \"italian\", \"ukbb\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load one subject each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_id = \"balgrist_1\"\n",
    "cro_id = \"croatian_1\"\n",
    "it_id = \"italian_10\"\n",
    "ukbb_id = \"ukbb_1238\"\n",
    "\n",
    "backscan_bal = o3d.io.read_point_cloud(str(path / bal_id / f\"{bal_id}_processed.ply\"))\n",
    "backscan_cro = o3d.io.read_point_cloud(str(path / cro_id / f\"{cro_id}_processed.ply\"))\n",
    "backscan_it = o3d.io.read_point_cloud(str(path / it_id / f\"{it_id}_processed.ply\"))\n",
    "backscan_ukbb = o3d.io.read_point_cloud(\n",
    "    str(path / ukbb_id / f\"{ukbb_id}_processed.ply\")\n",
    ")\n",
    "\n",
    "with open(path / bal_id / f\"{bal_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_bal = json.load(f)\n",
    "\n",
    "with open(path / cro_id / f\"{cro_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_cro = json.load(f)\n",
    "\n",
    "with open(path / it_id / f\"{it_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_it = json.load(f)\n",
    "\n",
    "with open(path / ukbb_id / f\"{ukbb_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_ukbb = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keys = {}\n",
    "\n",
    "metadata_keys[\"balgrist\"] = metadata_bal.keys()\n",
    "metadata_keys[\"croatian\"] = metadata_cro.keys()\n",
    "metadata_keys[\"italian\"] = metadata_it.keys()\n",
    "metadata_keys[\"ukbb\"] = metadata_ukbb.keys()\n",
    "\n",
    "metadata_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common keys: id, dataset, age, gender, pcDicomOutput, SpecialPts, esl, isl, status, pipelineSteps\n",
    "\n",
    "Balgrist, italian, ukbb: height, weight, recordingTime, operations\n",
    "\n",
    "Balgrist-only: recordingDatetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_bal[\"isl\"].keys())\n",
    "print(metadata_cro[\"isl\"].keys())\n",
    "print(metadata_it[\"isl\"].keys())\n",
    "print(metadata_ukbb[\"isl\"].keys())\n",
    "\n",
    "print(metadata_bal[\"esl\"].keys())\n",
    "print(metadata_cro[\"esl\"].keys())\n",
    "print(metadata_it[\"esl\"].keys())\n",
    "print(metadata_ukbb[\"esl\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Balgrist and UKBB, the esl and isl dictionary keys are 'pcdicomApp'. For croatian the esl and isl dictionary keys are 'formetric'. The italian dataset has both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balgrist ESL: \", np.asarray(metadata_bal[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Croatian ESL: \", np.asarray(metadata_cro[\"isl\"][\"formetric\"]).shape)\n",
    "print(\"Italian pcdicomapp ESL: \", np.asarray(metadata_it[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Italian ESL formetric: \", np.asarray(metadata_it[\"isl\"][\"formetric\"]).shape)\n",
    "print(\"UKBB ESL:\", np.asarray(metadata_ukbb[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "\n",
    "print(\"Balgrist ISL: \", np.asarray(metadata_bal[\"esl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Croatian ISL: \", np.asarray(metadata_cro[\"esl\"][\"formetric\"]).shape)\n",
    "print(\"Italian pcdicomapp ISL: \", np.asarray(metadata_it[\"esl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Italian formetric ISL: \", np.asarray(metadata_it[\"esl\"][\"formetric\"]).shape)\n",
    "print(\"UKBB ISL:\", np.asarray(metadata_ukbb[\"esl\"][\"pcdicomapp\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(metadata_it[\"isl\"][\"pcdicomapp\"])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore backscans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balgrist backscan: \", backscan_bal)\n",
    "print(\"Croatian backscan: \", backscan_cro)\n",
    "print(\"Italian backscan: \", backscan_it)\n",
    "print(\"UKBB backscan: \", backscan_ukbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dirs = dirs_df[dirs_df[\"processed\"] == True]\n",
    "\n",
    "datasets = [\"croatian\", \"italian\", \"balgrist\", \"ukbb\"]\n",
    "\n",
    "sampled_dirs = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_dirs = processed_dirs[processed_dirs[\"backscan\"].str.contains(dataset)]\n",
    "    sampled_dirs += list(dataset_dirs.sample(4)[\"backscan\"])\n",
    "\n",
    "# load the backscan data\n",
    "backscans = [o3d.io.read_point_cloud(backscan) for backscan in sampled_dirs]\n",
    "\n",
    "# load the metadata\n",
    "metadatas = [\n",
    "    json.load(\n",
    "        open(backscan.replace(\"ply\", \"json\").replace(\"processed\", \"metadata_processed\"))\n",
    "    )\n",
    "    for backscan in sampled_dirs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the backscans in 3d on a 4x4 grid. Use the same scale for all axes\n",
    "\n",
    "dataset_titles = [\"Nado\", \"IRCCS\", \"UKBB\", \"Balgrist\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, backscan in enumerate(backscans):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, projection=\"3d\")\n",
    "\n",
    "    # color the points according to their z coordinate\n",
    "    c = np.asarray(backscan.points)[:, 2]\n",
    "    ax.scatter(\n",
    "        np.asarray(backscan.points)[:, 0],\n",
    "        np.asarray(backscan.points)[:, 2],\n",
    "        np.asarray(backscan.points)[:, 1],\n",
    "        c=c,\n",
    "        cmap=\"viridis\",\n",
    "        s=0.1,\n",
    "    )\n",
    "\n",
    "    # set lims to max coordinate of the backscan in any axis\n",
    "\n",
    "    lim_max, lim_min = np.max(np.abs(np.asarray(backscan.points))), -np.max(\n",
    "        np.abs(np.asarray(backscan.points))\n",
    "    )\n",
    "    ax.set_xlim(lim_min, lim_max)\n",
    "    ax.set_ylim(lim_min, lim_max)\n",
    "    ax.set_zlim(lim_min, lim_max)\n",
    "\n",
    "    # switch axis direction from negative to positive to positive to negative\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # remove grid, add axis labels in mm, add a title to each row with dataset\n",
    "    ax.set_xlabel(\"X (mm)\")\n",
    "    ax.set_ylabel(\"Z (mm)\")\n",
    "    ax.set_zlabel(\"Y (mm)\")\n",
    "\n",
    "    if i % 4 == 2:\n",
    "        ax.annotate(\n",
    "            dataset_titles[i // 4],\n",
    "            xy=(-0.15, 1.05),\n",
    "            xycoords=\"axes fraction\",\n",
    "            ha=\"center\",\n",
    "            fontsize=12,\n",
    "            fontfamily=\"serif\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spinediffusion.datamodule.transforms.projecting import ProjectToPlane\n",
    "\n",
    "projector = ProjectToPlane(128, 128, 0.9, 1, \"mean\")\n",
    "\n",
    "# project the backscans to the sagittal plane\n",
    "backscans_proj = []\n",
    "for backscan, metadata in zip(backscans, metadatas):\n",
    "    data_id = {}\n",
    "    data_id[\"backscan\"] = backscan\n",
    "    special_points = metadata[\"specialPts\"]\n",
    "    data_id[\"special_points\"] = {k: np.array(v) for k, v in special_points.items()}\n",
    "    backscans_proj.append(projector(data_id)[\"depth_map\"])\n",
    "\n",
    "# plot the projected backscans in 2d on a 4x4 grid\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, backscan_proj in enumerate(backscans_proj):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.imshow(backscan_proj.squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    if i % 4 == 2:\n",
    "        ax.annotate(\n",
    "            dataset_titles[i // 4],\n",
    "            xy=(-0.15, 1.05),\n",
    "            xycoords=\"axes fraction\",\n",
    "            ha=\"center\",\n",
    "            fontsize=12,\n",
    "            fontfamily=\"serif\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dirs_df = dirs_df[dirs_df[\"processed\"] == True]\n",
    "\n",
    "metadata = {}\n",
    "backscans = {}\n",
    "\n",
    "for backscan_dir, metadata_dir in tqdm(\n",
    "    zip(processed_dirs_df[\"backscan\"], processed_dirs_df[\"metadata\"]),\n",
    "    total=len(processed_dirs_df),\n",
    "):\n",
    "    with open(metadata_dir, \"r\") as f:\n",
    "        metadata_ = json.load(f)\n",
    "\n",
    "    unique_id = f\"{metadata_['dataset']}_{metadata_['id']}\"\n",
    "\n",
    "    metadata[unique_id] = metadata_\n",
    "    backscans[unique_id] = o3d.io.read_point_cloud(backscan_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backscans_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "esl_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "isl_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "for unique_id in metadata:\n",
    "    dataset = metadata[unique_id][\"dataset\"]\n",
    "    esl = metadata[unique_id][\"esl\"]\n",
    "    isl = metadata[unique_id][\"isl\"]\n",
    "\n",
    "    backscans_dataset[dataset].append(backscans[unique_id])\n",
    "    esl_dataset[dataset].append(esl)\n",
    "    isl_dataset[dataset].append(isl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize point distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in backscans_dataset:\n",
    "    points = np.concatenate(\n",
    "        [np.asarray(pc.points) for pc in backscans_dataset[dataset]]\n",
    "    )\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in esl_dataset:\n",
    "    key = \"pcdicomapp\"\n",
    "    if dataset == \"croatian\":\n",
    "        key = \"formetric\"\n",
    "    points = np.concatenate([np.asarray(pc[key]) for pc in esl_dataset[dataset]])\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in esl_dataset:\n",
    "    key = \"pcdicomapp\"\n",
    "    if dataset == \"croatian\":\n",
    "        key = \"formetric\"\n",
    "    points = np.concatenate([np.asarray(pc[key]) for pc in esl_dataset[dataset]])\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique_id in metadata:\n",
    "    fix_points = np.asarray(metadata[unique_id][\"fix_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"balgrist_10\"][\"specialPts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"balgrist_1\"][\"specialPts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get common pipelineSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_steps = []\n",
    "order = []\n",
    "\n",
    "for unique_id in metadata:\n",
    "    pipeline_steps.append(metadata[unique_id][\"pipelineSteps\"])\n",
    "    order.append(metadata[unique_id][\"pipelineSteps\"][\"order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(order[0]).intersection(*order[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline steps applied to all samples (above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_steps[0][\"preprocessing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.asarray(pc.points)\n",
    "\n",
    "points = points / points.max(axis=0)\n",
    "\n",
    "norm_pc = o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([norm_pc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
