{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Workspace setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Count number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"P:\\\\Projects\\\\LMB_4Dspine\\\\back_scan_database\")\n",
    "\n",
    "backscan_dirs = glob.glob(str(path / \"**\" / \"*.ply\"))\n",
    "metadata_dirs = glob.glob(str(path / \"**\" / \"*.json\"))\n",
    "\n",
    "dirs_df = pd.DataFrame({\"backscan\": backscan_dirs, \"metadata\": metadata_dirs})\n",
    "dirs_df[\"raw\"] = dirs_df[\"backscan\"].str.contains(\"raw\")\n",
    "dirs_df[\"processed\"] = dirs_df[\"backscan\"].str.contains(\"processed\")\n",
    "\n",
    "dirs_df[\"balgrist\"] = dirs_df[\"backscan\"].str.contains(\"balgrist\")\n",
    "dirs_df[\"croatian\"] = dirs_df[\"backscan\"].str.contains(\"croatian\")\n",
    "dirs_df[\"italian\"] = dirs_df[\"backscan\"].str.contains(\"italian\")\n",
    "dirs_df[\"ukbb\"] = dirs_df[\"backscan\"].str.contains(\"ukbb\")\n",
    "\n",
    "dirs_df.groupby(\"raw\")[[\"balgrist\", \"croatian\", \"italian\", \"ukbb\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load one subject each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_id = \"balgrist_1\"\n",
    "cro_id = \"croatian_1\"\n",
    "it_id = \"italian_10\"\n",
    "ukbb_id = \"ukbb_1238\"\n",
    "\n",
    "backscan_bal = o3d.io.read_point_cloud(str(path / bal_id / f\"{bal_id}_processed.ply\"))\n",
    "backscan_cro = o3d.io.read_point_cloud(str(path / cro_id / f\"{cro_id}_processed.ply\"))\n",
    "backscan_it = o3d.io.read_point_cloud(str(path / it_id / f\"{it_id}_processed.ply\"))\n",
    "backscan_ukbb = o3d.io.read_point_cloud(\n",
    "    str(path / ukbb_id / f\"{ukbb_id}_processed.ply\")\n",
    ")\n",
    "\n",
    "with open(path / bal_id / f\"{bal_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_bal = json.load(f)\n",
    "\n",
    "with open(path / cro_id / f\"{cro_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_cro = json.load(f)\n",
    "\n",
    "with open(path / it_id / f\"{it_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_it = json.load(f)\n",
    "\n",
    "with open(path / ukbb_id / f\"{ukbb_id}_metadata_processed.json\", \"r\") as f:\n",
    "    metadata_ukbb = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keys = {}\n",
    "\n",
    "metadata_keys[\"balgrist\"] = metadata_bal.keys()\n",
    "metadata_keys[\"croatian\"] = metadata_cro.keys()\n",
    "metadata_keys[\"italian\"] = metadata_it.keys()\n",
    "metadata_keys[\"ukbb\"] = metadata_ukbb.keys()\n",
    "\n",
    "metadata_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common keys: id, dataset, age, gender, pcDicomOutput, SpecialPts, esl, isl, status, pipelineSteps\n",
    "\n",
    "Balgrist, italian, ukbb: height, weight, recordingTime, operations\n",
    "\n",
    "Balgrist-only: recordingDatetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_bal[\"isl\"].keys())\n",
    "print(metadata_cro[\"isl\"].keys())\n",
    "print(metadata_it[\"isl\"].keys())\n",
    "print(metadata_ukbb[\"isl\"].keys())\n",
    "\n",
    "print(metadata_bal[\"esl\"].keys())\n",
    "print(metadata_cro[\"esl\"].keys())\n",
    "print(metadata_it[\"esl\"].keys())\n",
    "print(metadata_ukbb[\"esl\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Balgrist and UKBB, the esl and isl dictionary keys are 'pcdicomApp'. For croatian the esl and isl dictionary keys are 'formetric'. The italian dataset has both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balgrist ESL: \", np.asarray(metadata_bal[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Croatian ESL: \", np.asarray(metadata_cro[\"isl\"][\"formetric\"]).shape)\n",
    "print(\"Italian pcdicomapp ESL: \", np.asarray(metadata_it[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Italian ESL formetric: \", np.asarray(metadata_it[\"isl\"][\"formetric\"]).shape)\n",
    "print(\"UKBB ESL:\", np.asarray(metadata_ukbb[\"isl\"][\"pcdicomapp\"]).shape)\n",
    "\n",
    "print(\"Balgrist ISL: \", np.asarray(metadata_bal[\"esl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Croatian ISL: \", np.asarray(metadata_cro[\"esl\"][\"formetric\"]).shape)\n",
    "print(\"Italian pcdicomapp ISL: \", np.asarray(metadata_it[\"esl\"][\"pcdicomapp\"]).shape)\n",
    "print(\"Italian formetric ISL: \", np.asarray(metadata_it[\"esl\"][\"formetric\"]).shape)\n",
    "print(\"UKBB ISL:\", np.asarray(metadata_ukbb[\"esl\"][\"pcdicomapp\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(metadata_it[\"isl\"][\"pcdicomapp\"])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore backscans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balgrist backscan: \", backscan_bal)\n",
    "print(\"Croatian backscan: \", backscan_cro)\n",
    "print(\"Italian backscan: \", backscan_it)\n",
    "print(\"UKBB backscan: \", backscan_ukbb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dirs_df = dirs_df[dirs_df[\"processed\"] == True]\n",
    "\n",
    "metadata = {}\n",
    "backscans = {}\n",
    "\n",
    "for backscan_dir, metadata_dir in tqdm(\n",
    "    zip(processed_dirs_df[\"backscan\"], processed_dirs_df[\"metadata\"]),\n",
    "    total=len(processed_dirs_df),\n",
    "):\n",
    "    with open(metadata_dir, \"r\") as f:\n",
    "        metadata_ = json.load(f)\n",
    "\n",
    "    unique_id = f\"{metadata_['dataset']}_{metadata_['id']}\"\n",
    "\n",
    "    metadata[unique_id] = metadata_\n",
    "    backscans[unique_id] = o3d.io.read_point_cloud(backscan_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backscans_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "esl_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "isl_dataset = {\n",
    "    \"balgrist\": [],\n",
    "    \"croatian\": [],\n",
    "    \"italian\": [],\n",
    "    \"ukbb\": [],\n",
    "}\n",
    "\n",
    "for unique_id in metadata:\n",
    "    dataset = metadata[unique_id][\"dataset\"]\n",
    "    esl = metadata[unique_id][\"esl\"]\n",
    "    isl = metadata[unique_id][\"isl\"]\n",
    "\n",
    "    backscans_dataset[dataset].append(backscans[unique_id])\n",
    "    esl_dataset[dataset].append(esl)\n",
    "    isl_dataset[dataset].append(isl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize point distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in backscans_dataset:\n",
    "    points = np.concatenate(\n",
    "        [np.asarray(pc.points) for pc in backscans_dataset[dataset]]\n",
    "    )\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in esl_dataset:\n",
    "    key = \"pcdicomapp\"\n",
    "    if dataset == \"croatian\":\n",
    "        key = \"formetric\"\n",
    "    points = np.concatenate([np.asarray(pc[key]) for pc in esl_dataset[dataset]])\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in esl_dataset:\n",
    "    key = \"pcdicomapp\"\n",
    "    if dataset == \"croatian\":\n",
    "        key = \"formetric\"\n",
    "    points = np.concatenate([np.asarray(pc[key]) for pc in esl_dataset[dataset]])\n",
    "    x, y, z = points.T\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    axs[0].hist(x, bins=100, color=\"r\", alpha=0.7)\n",
    "    axs[0].set_title(f\"{dataset} x-axis\")\n",
    "    axs[0].set_xlabel(\"x-axis\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[1].hist(y, bins=100, color=\"g\", alpha=0.7)\n",
    "    axs[1].set_title(f\"{dataset} y-axis\")\n",
    "    axs[1].set_xlabel(\"y-axis\")\n",
    "    axs[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    axs[2].hist(z, bins=100, color=\"b\", alpha=0.7)\n",
    "    axs[2].set_title(f\"{dataset} z-axis\")\n",
    "    axs[2].set_xlabel(\"z-axis\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique_id in metadata:\n",
    "    fix_points = np.asarray(metadata[unique_id][\"fix_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"balgrist_10\"][\"specialPts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"balgrist_1\"][\"specialPts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get common pipelineSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_steps = []\n",
    "order = []\n",
    "\n",
    "for unique_id in metadata:\n",
    "    pipeline_steps.append(metadata[unique_id][\"pipelineSteps\"])\n",
    "    order.append(metadata[unique_id][\"pipelineSteps\"][\"order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(order[0]).intersection(*order[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline steps applied to all samples (above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_steps[0][\"preprocessing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.asarray(pc.points)\n",
    "\n",
    "points = points / points.max(axis=0)\n",
    "\n",
    "norm_pc = o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([norm_pc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
