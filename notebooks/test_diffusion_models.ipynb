{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "from spinediffusion.datamodule.datamodule import SpineDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_config = config[\"data\"][\"init_args\"]\n",
    "data_config[\"n_subjects\"] = 5\n",
    "data_config[\"use_cache\"] = False\n",
    "data_config[\"transform_args\"][\"project_to_plane\"][\"height\"] = 128\n",
    "data_config[\"transform_args\"][\"project_to_plane\"][\"width\"] = 128\n",
    "\n",
    "\n",
    "data_module = SpineDataModule(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data_module.train_data[0][\"depth_map\"].unsqueeze(0).type(torch.float32)\n",
    "img_size = img.shape[-1]\n",
    "\n",
    "model = UNet2DModel(\n",
    "    img_size,  # the target image resolution\n",
    "    in_channels=1,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=1,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(\n",
    "        128,\n",
    "        128,\n",
    "        256,\n",
    "        256,\n",
    "        512,\n",
    "        512,\n",
    "    ),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(img.shape)\n",
    "timesteps = torch.LongTensor([50])\n",
    "noisy_image = scheduler.add_noise(img, noise, timesteps)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(img[0, 0], cmap=\"gray\")\n",
    "axs[1].imshow(noisy_image[0, 0], cmap=\"gray\")\n",
    "axs[2].imshow(noisy_image[0, 0] - img[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred = model(noisy_image, timesteps).sample\n",
    "loss = F.mse_loss(noise_pred, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(noise[0, 0], cmap=\"gray\")\n",
    "axs[1].imshow(noise_pred.detach().numpy()[0, 0], cmap=\"gray\")\n",
    "axs[2].imshow(noise_pred.detach().numpy()[0, 0] - noise.numpy()[0, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../configs/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spinediffusion.models.diffusion_models import DepthMapDiffusionModel\n",
    "from diffusers import UNet2DModel, DDPMScheduler, get_cosine_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "model = UNet2DModel(**config[\"model\"][\"init_args\"][\"model\"][\"init_args\"])\n",
    "scheduler = DDPMScheduler(**config[\"model\"][\"init_args\"][\"scheduler\"][\"init_args\"])\n",
    "optimizer = torch.optim.AdamW\n",
    "lr_scheduler = get_cosine_schedule_with_warmup\n",
    "loss = torch.nn.MSELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = DepthMapDiffusionModel(model, scheduler, optimizer, lr_scheduler, 0.001, loss, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
